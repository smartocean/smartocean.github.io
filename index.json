
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Alice Wu is a professor of artificial intelligence at the Stanford AI Lab. Her research interests include distributed robotics, mobile computing and programmable matter. She leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\n","date":1554595200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Alice Wu is a professor of artificial intelligence at the Stanford AI Lab. Her research interests include distributed robotics, mobile computing and programmable matter. She leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.","tags":null,"title":"智慧海洋实验室","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://smartocean.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["智慧海洋实验室","大盘小海盗团队"],"categories":[],"content":"水空两栖探测航行器分为两部分，分别是水下观测的自主遥控水下机器人（ARV）以及携带ARV飞抵目标海域的八旋翼无人机。通过八旋翼的绞盘收纳装置实现ARV的自主收纳与释放过程。可对极地季节性冰区、北温带海冰等人类及传统水下观测航行器难以抵达的海域进行海空一体探测。\n演示视频 项目背景 现阶段，物联网快速发展，全自动化日益普及，完全无人探测的实现指日可待。与此同时，针对复杂水域实现空中运动的需求也逐渐增强。在此方面，市面上目前的同类型产品都能够实现一定范围内的运动、探测等功能，一些相关无人机也曾对水空两栖探测进行过探索，例如：ETH Zurich所生产的机器人Dipper能够实现在空中和水下的受控运动，兼具飞行和潜水功能的无人机Naviator，以及填补了国内大型水空两用无人机空白的——中国上海优伟斯智能系统有限公司所生产的机器人U650。\n然而，在一定程度上，它们都或多或少地存在着一些局限性与不足，如：体积较大，在探测有障碍的海域时行动不便、动作不灵活，性能不全面，实现两栖运动功能的同时无法实现探测目标，以及其最主要的局限性：运动基本仅针对单一目标领域，导致对复杂环境的处理能力不强。而随着技术的发展与能源需求的提高，极地地区的科研勘测意义愈发重要。极地地区多为冰区，海域情况复杂，水面多浮冰，水下多陡崖、暗流，出现紧急情况的概率大。而在现实情况中，极地地区的海域受天气与洋流的影响，更加变化莫测，这也对适用于极地勘测的两栖探测机器人的设计提出了更高的要求。因此，我们将构建一个水空两栖航行器对该问题进行优化和解决，这有望广泛应用于海上搜救、海洋科学等领域；实现对特定海区同时进行水空探测的任务；适配于冰层、冰下等复杂环境中的作业任务。\n具体内容： 本产品面向极地季节性冰区的探测工作，是一种能够实现“空中-水上-水下”一体化探测的分体式两栖航行器，其目的是实现“水空两栖”，实现穿越浮冰较多、小型无人船难以通行的复杂冰区，并于冰区内部释放自主水下航行器，进行冰下光场的数据搜集、探测冰层、救援等任务，让两个分体的部分发挥“一加一大于二”的效果。其分体式的设计与高度定制化的飞控系统使其更易操控、调试，并且面对复杂环境时的鲁棒性更强。同时，高开发程度的系统与大部分开源并且互相独立的组件也让其功能更加灵活，降低了二次开发的门槛，为进一步发展提供了更广阔的可能性。\n项目的核心技术及特色为：分体式结构设计与控制，八旋翼无人机搭载小型自主/遥控水下航行器实现水下航行器的释放、自主回收等动作。从控制上，设计要求无人机与水下航行器进行相互协同，进行自主的协同工作。例如无人机实时将冰区整体结构发送至水下航行器，帮助水下航行器进行水下定位与导航等工作。为分体式控制领域提供了更为灵活的解决方案。\n创新点：\n八旋翼无人机与自主/遥控水下航行器（ARV）分体式设计，水空两栖、应对场景灵活。并且ARV动力结构采用六自由度全矢量布局，机动灵活。\n**系统性能和安全性：**ARV与八旋翼无人机采用独立的供电系统及控制系统，保证了整体系统的鲁棒性。并且ARV与无人机采用ROS系统进行协同控制，确保“分体如一体”。\n现实及潜在应用：可用于极地季节性冰区及北温带海冰环境的水下探测任务。\n设计方案 无人机设计 无人机结构设计 整机采用八旋翼驱动方式：首先因为其在结构上高度对称，可实现在空中不考虑所面对方向实现全方位移动；并且八轴会给整套系统提供更大的升力，可在进行ARV水质监测作业等负重作业环境中中实现高负载的要求；最后由于考虑到极地强风的特殊地理环境，为保证整套系统的的稳定性，因此在该项目中采用八旋翼无人机。\n整机采用全碳纤维机架结构，在保证整体轻量化的同时还保证了机体结构的强度和稳定性，采用Sunnysky朗宇X4110S无刷电机啊搭配DJI1555桨叶，单电机最大功率达到500W以上，实现全机负载12Kg，搭配轻量化ARV可实现大部分特殊场景作业。\n为实现无人机部分在水面部分的悬浮，在每个桨叶下面配备浮漂，并且根据物理场仿真验证，浮漂对机体的升力影响小于10%，并且将浮漂设置在无人机臂边侧，当在极地环境机体受到浮冰碰撞时，浮漂也会抵挡部分冲击力防止损伤到重要机体结构。并且根据力学仿真分析，边侧浮漂当受到浪等波动时，其拥有自适应姿态反馈调节以保证机体在水面上的稳定性。\n无人机电控设计 首先，对于重要的操控部件遥控器，本产品使用RadioMaster开源遥控器，在无人机模式，遥控器连接八旋翼无人机的可编程的飞控，手动操控无人机的飞行。当无人机降落到水面之后，可以仅仅通过遥控器信道的切换，转换至水下航行器的控制模式。与此同时，考虑到电信号在水中的传播衰减很大，水下航行器的接收机被安装在浮在水面的无人机上，并通过脐带缆与水下航行器相连。\n对于地面基站，其主要作用有三点：分别是任务规划、操作控制和显示记录。其中，任务规划功能主要包括飞行航路规划与重规划、任务载荷工作规划与重规划；操作控制功能主要包括起降操纵、飞行控制操作、任务载荷操作、数据链控制，实现了高度自动化的功能；而显示记录功能主要包括飞行状态参数显示与记录、航迹显示与记录、载荷信息显示与记录。此外，通过地面站的控制，水下机器人也能实现图传功能。\n针对复杂冰区自动化进行水面着陆的特殊要求，团队使用OpenCV自主开发了一款能够自动识别冰区与海面的全自动视觉识别系统。利用冰面反射率较海面更高的特点，视觉识别系统灵敏度高，鲁棒性强，能成功完成自动海上着陆的引导要求。\n冰区水下航行器设计 水下航行器结构设计 整机采用六推进器实现六自由度全矢量布局，推进器方面选择强度高、耐腐蚀、耐海水的T60水下推进器，单个电机功率可达到300W。\n在机身材料方面采用全3D打印（ABS）制作，使得保证强度的情况下，实现ARV轻量化进行作业任务，也可减轻对无人机携带的负担，以此提高整体结构的工作覆盖范围。\n为适应极地低温环境，将ARV的电子仓和电池仓合并，使得树莓派等电子元件在工作时的产热将提供到环境中保证电池的正常放电，并且在ARV防水仓内壁填充了高性能发泡材料，减少外界与防水仓内的热交换。为防止电池电能释放效率过低，在仓内加装了温度传感器以及电加热片，当温度过低时，将自动开启电加热片以保证电能的释放。\n在结构设计方面采用环绕式支架布局，并且在中段设置了可微调距离的套环，可实现自适应安装，保证整机的抗破坏性以及结构强度。并且环绕式支架结构可在后期需要安装抓手以及探测传感器时，在预留位置进行安装，其拓展性和开放性良好，并且紧凑式布局将整机的尺寸压缩到了300*300*200内，可通过狭小冰裂缝区\n域进行特殊地形的观测任务等。\n","date":1682474762,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682474762,"objectID":"36f8ae3839748fe1afe9b8da23c91840","permalink":"https://smartocean.github.io/project/dragonfly-arv/","publishdate":"2023-04-26T10:06:02+08:00","relpermalink":"/project/dragonfly-arv/","section":"project","summary":"通过八旋翼的绞盘收纳装置实现ARV的自主收纳与释放过程。可对极地季节性冰区、北温带海冰等人类及传统水下观测航行器难以抵达的海域进行海空一体探测。","tags":["航行器"],"title":"“腾蛇号”面向极地季节性冰区的两栖航行器","type":"project"},{"authors":["智慧海洋实验室AI与算法小组","面壁的雨"],"categories":[],"content":" 本文首发于牧雨博客\nhttps://www.everains.com/note/ar339.html\n问题重述 构建卷积神经网络模型（CNN）对fashion-mnist数据集进行分类(10类)。\n数据简介 FashionMNIST 是一个替代 MNIST 手写数字集的图像数据集。 它是由 Zalando（一家德国的时尚科技公司）旗下的研究部门提供。其涵盖了来自 10 种类别的共 7 万个不同商品的正面图片,分别是：t-shirt（T恤），trouser（牛仔裤），pullover（套衫），dress（裙子），coat（外套）,sandal（凉鞋），shirt（衬衫），sneaker（运动鞋），bag（包），ankle boot（短靴）。\nFashionMNIST 的大小、格式和训练集/测试集划分与原始的 MNIST 完全一致。60000/10000 的训练测试数据划分，28×28 的灰度图片。你可以直接用它来测试你的机器学习和深度学习算法性能，且不需要改动任何的代码（实测跑mnist的模型用在fashion上的准确率能到60%）。\n这个数据集的样子大致如下（每个类别占三行）：\n数据读取及预处理 使用Keras模块可以轻松导入\nfrom keras.datasets import fashion_mnist (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data() x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)/255 x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)/255 y_train = to_categorical(y_train) y_test = to_categorical(y_test) 其中，首先使用reshape函数将x_train,x_test张量形状转为(60000, 28, 28, 1),(10000, 28, 28, 1)这一四阶张量,这意味着训练样本数量为60000份测试样本数量为10000份，每张样本图像大小为28*28。由于每个样本的像素值是0至255之间的值，因此在训练网络之前进行了归一化的操作。\n而y_train,y_test则存储每个样本所对应的服装种类，用1~10表示。\n模型建立 模型方面，参考了VGG网络结构[^1]，大致特征为：\n使用连续的小卷积核(3×3)做连续卷积，卷积的固定步长为1，并在图像的边缘填充1个像素，这样卷积后保持图像的分辨率不变。 连续的卷积层会接着一个池化层，降低图像的分辨率。空间池化由两个最大池化层进行，并在2×2像素窗口上进行最大池化。 卷积层后，接着的是3个全连接层，前两个分别为512、64个通道，第三是输出层输出10个分类。 每个隐藏层的激活函数均使用ReLU。 使用多次Dropout，以避免多次训练后的过拟合问题（具体表现为损失率后期增高）。 以下为网络详细结构\nModel: \u0026#34;sequential_1\u0026#34; ______________________________________________________________ Layer (type) Output Shape Param # ============================================================== conv2d_6 (Conv2D) (None, 28, 28, 32) 320 ______________________________________________________________ conv2d_7 (Conv2D) (None, 28, 28, 32) 9248 ______________________________________________________________ dropout_5 (Dropout) (None, 28, 28, 32) 0 ______________________________________________________________ conv2d_8 (Conv2D) (None, 28, 28, 64) 18496 ______________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64) 0 ______________________________________________________________ dropout_6 (Dropout) (None, 14, 14, 64) 0 ______________________________________________________________ conv2d_9 (Conv2D) (None, 14, 14, 128) 73856 ______________________________________________________________ conv2d_10 (Conv2D) (None, 14, 14, 128) 147584 ______________________________________________________________ conv2d_11 (Conv2D) (None, 14, 14, 256) 295168 ______________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 7, 7, 256) 0 ______________________________________________________________ dropout_7 (Dropout) (None, 7, 7, 256) 0 ______________________________________________________________ flatten_1 (Flatten) (None, 12544) 0 ______________________________________________________________ dense_3 (Dense) (None, 512) 6423040 ______________________________________________________________ dropout_8 (Dropout) (None, 512) 0 ______________________________________________________________ dense_4 (Dense) (None, 64) 32832 ______________________________________________________________ dropout_9 (Dropout) (None, 64) 0 ______________________________________________________________ dense_5 (Dense) (None, 10) 650 ============================================================== Total params: 7,001,194 Trainable params: 7,001,194 Non-trainable params: 0 分析结果 训练精度 泛化精度 训练误差 泛化误差 0.9684 0.9304 0.0909 0.2591 可以看出，各精度指标均在93%以上，模型较好。\n但通过图表可以观察到，在第10次学习后，泛化误差开始明显上升，说明出现过拟合问题，这一点或许可以通过增加Dropout、加大网络深度及降低学习率解决。\n优化方向 在进行卷积操作时，本模型使用的方法是采用边界填充（Padding）操作，在图像外围填充数值0，再进行卷积操作，经过一次卷积后输出的特征图矩阵与输入的图像矩阵有相同的大小，解决训练深度受限的问题.但此方法会使图像边缘信息模糊，导致在一定程度上降低准确度。而如果在每一步对padding操作进行权重化，根据相关研究，可能将准确度提升至多1.52%[^2]。\n参考 [^1]: [1409.1556] Very Deep Convolutional Networks for Large-Scale Image Recognition\n[^2]: 刘之瑜. 基于Padding权重化的卷积神经网络研究[J]. New Generation of Information Technology, 2021, 4(3):14-20.\n[^3]: https://www.kaggle.com/gpreda/cnn-with-tensorflow-keras-for-fashion Accessed at 2021/10/15\n","date":1682412401,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682412401,"objectID":"4789077aac5ee5bd37ab7a4a064a7c5e","permalink":"https://smartocean.github.io/post/mnist-fashion-cnn-network/","publishdate":"2023-04-25T16:46:41+08:00","relpermalink":"/post/mnist-fashion-cnn-network/","section":"post","summary":"等待AI总结中。。。","tags":[],"title":"基于Mnist Fashion数据集的卷积神经网络","type":"post"},{"authors":["周一唱"],"categories":[],"content":"研究背景 随着智能机器人行业的快速发展，地面作业对机器人的依赖也越来越高。面对实际情况中的复杂地形，球-腿双形态机器人兼具球形机器人快速运动和多足机器人高避障能力的特点，具有更强的适应能力，是突破当前单形态机器人作业局限的重要发展方向。\n产品概述 本产品为一种具有不同形态的智能机器人系统，本产品特殊的腿部结构使其可以实现在球形机器人和六足机器人之间进行形态切换，以满足面向复杂环境进行探测作业的要求。同时其灵活的结构设计和开放的系统设置不仅能更好地满足用户的个性化需求，还降低了用户二次开发的门槛，为进一步发展提供了更广阔的可能性。\n产品设计 本产品由特殊设计结构的下位机、拥有对应遥控能力的上位机系统组成， 同时为其编写了适用于多种运动形态的智能算法。\n按照设计规划，下位机有着为多形态变换而设计的腿部结构，整体将满足以下几点需求：机器人结构坚固耐用，具有一定的抗冲击能力；运动结构之间配合良好，在变形及运动过程中不发生结构干涉；同时内部留有足够的空间搭载摄像头等传感器。\n开发的上位机将能显示机器人的实时状态（包含所处形态、运动速度、平台位姿、位置、剩余电量等信息）；能远程对机器人的动作进行操作；可以接收摄像头、激光雷达等用于探测的传感器返回的画面信息，并封装图像识别功能。\n智能算法的研究内容包括：统合机器人的多种运动形态；使机器人具有通过传感器回传的数据判断周围环境，并自动切换形态的能力；具有在划定巡航区域\n后，自主规划巡航路径的能力；具有能根据剩余电量自主判断巡航返程时间的能力。\n产品核心创新 结构上，本产品为双形态机器人，可以在球形态与足式形态之间自由切换以满足不同情况的需求。球形态适合在平坦路面及上下坡路面行驶；足式形态适合在崎岖复杂的地形下行驶，并且在足式形态下，本产品还具有一定的负载和运载能力。独特的球形结构设计，能让本产品在受到外部冲击时能分散应力分布，使产品结构坚固稳定，具有一定的抗冲击能力。\n功能上，本产品可自由搭配多种传感器，以满足不同场景的需求。双形态结构自由切换可以灵活应对复杂路况，搭载摄像头，红外成像仪，气体传感器，土壤湿度传感器等设备，可以进行野外环境探测以及搜救任务。搭载摄像头，心率传感器等，可以用作居家陪护，方便用户对家里老人和小孩的监护。\n本产品留有扩展接口，方便用户进行二次开发，并满足用户个性化定制需求。本产品系统有着较高的开放度，降低了用户二次开发门槛。且本产品的灵活结构决定了其拥有较为广阔的二次开发前景，如多个球-腿符合机器人的协同作业、地面多形态机器人和无人机的协同作业等，将发挥一加一大于二的效果。\n","date":1682411563,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682411563,"objectID":"c1a00886a3501907e382a5dd8d69d1b9","permalink":"https://smartocean.github.io/project/masterball-robot/","publishdate":"2023-04-25T16:32:43+08:00","relpermalink":"/project/masterball-robot/","section":"project","summary":"MasterBall ","tags":["机器人"],"title":"MasterBall | 大师球双形态机器人","type":"project"},{"authors":["智慧海洋实验室"],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://smartocean.github.io/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://smartocean.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["智慧海洋实验室","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://smartocean.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["智慧海洋实验室","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://smartocean.github.io/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"}]